{
    "config": [
        {
            "title": "Number of requests",
            "type": "REQUEST_COUNT",
            "queries": [
                {
                    "title": "Number of successful incoming requests",
                    "query": "round(sum(increase(vllm:request_success_total{namespace='${NAMESPACE}',model_name='${model_name}'}[${RATE_INTERVAL}])))"
                }
            ]
        },
        {
            "title": "Average response time (ms)",
            "type": "MEAN_LATENCY",
            "queries": [
                {
                    "title": "Average e2e latency",
                    "query": "histogram_quantile(0.5, sum(rate(vllm:e2e_request_latency_seconds_bucket{namespace='${NAMESPACE}', model_name='${MODEL_NAME}'}[${RATE_INTERVAL}])) by (le, model_name))"
                }
            ]
        },
        {
            "title": "CPU utilization %",
            "type": "CPU_USAGE",
            "queries": [
                {
                    "title": "CPU usage",
                    "query":  "sum(pod:container_cpu_usage:sum{namespace='${NAMESPACE}', pod=~'${MODEL_NAME}-predictor-.*'})/sum(kube_pod_resource_limit{resource='cpu', pod=~'${MODEL_NAME}-predictor-.*', namespace='${NAMESPACE}'})"
                }
            ]
        },
        {
            "title": "Memory utilization %",
            "type": "MEMORY_USAGE",
            "queries": [
                {
                    "title": "Memory usage",
                    "query":  "sum(container_memory_working_set_bytes{namespace='${NAMESPACE}', pod=~'${MODEL_NAME}-predictor-.*'})/sum(kube_pod_resource_limit{resource='memory', pod=~'${MODEL_NAME}-predictor-.*', namespace='${NAMESPACE}'})"
                }
            ]
        }
    ]
}